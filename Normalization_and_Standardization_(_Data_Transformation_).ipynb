{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6sC1laPc0fgg/C7nz1luL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshayy-ai/Machine-Learning/blob/main/Normalization_and_Standardization_(_Data_Transformation_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalization**\n",
        "\n",
        "Let's take example\n",
        "\n",
        "We've following columns\n",
        "\n",
        "```\n",
        "Salary  |  Exp\n",
        "---------------\n",
        "10000   |   2\n",
        "87000   |   4\n",
        "159999  |   6\n",
        "50000   |   3\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "So if we try to plot this values there is very huge diffrence betwwen scales so we use Normalization\n",
        "\n",
        "**Range : [0,1] or [-1,1]**\n",
        "\n"
      ],
      "metadata": {
        "id": "b4Z_AChWkpDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TShRbkGljmX8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "01RfNGKQj5ST"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Numpy Array\n",
        "\n",
        "numpy_array=np.array([2,3,5,7,16,32,44,80,150,300])\n",
        "print(numpy_array)\n",
        "normalized_array=preprocessing.normalize([numpy_array])\n",
        "print(normalized_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFsnxA8UkAlQ",
        "outputId": "bc434b0e-7ac3-4772-8eb8-00fcf0f6dc42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2   3   5   7  16  32  44  80 150 300]\n",
            "[[0.00572123 0.00858184 0.01430306 0.02002429 0.0457698  0.09153961\n",
            "  0.12586696 0.22884902 0.42909191 0.85818382]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Standardization**\n",
        "\n",
        "Mean and Standard Deviation is used for scaling\n",
        "\n",
        "**Range : Not Bounded to any certain range**"
      ],
      "metadata": {
        "id": "o1t6EFTllze9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data =[[0,0],[0,0],[1,1],[2,2]]\n",
        "print(data)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data)\n",
        "print(scaler.transform(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJyXvrH-lyh7",
        "outputId": "5b3a2f25-52fc-41a5-e986-134d1d14c63a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0], [1, 1], [2, 2]]\n",
            "[[-0.90453403 -0.90453403]\n",
            " [-0.90453403 -0.90453403]\n",
            " [ 0.30151134  0.30151134]\n",
            " [ 1.50755672  1.50755672]]\n"
          ]
        }
      ]
    }
  ]
}